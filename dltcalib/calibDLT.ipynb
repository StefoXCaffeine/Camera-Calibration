{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ASSIGNMENT 1: CAMERA CALIBRATION\n",
    "\n",
    "Nel seguente notebook è stato implementato il codice necessario per la calibrazione di una camera tramite Direct Linear Transformation, ottenendo la matrice dei paramentri intrinseci(dipendenti da tipo e modello della camera, come lunghezza focale e aspect ratio dell'immagine), i parametri estrinseci(matrice di rotazione e vettore di traslazione che identificano la posa della camera nell'ambiente) e la matrice della camera P, necessaria per proiettare i punti tridimensionali del mondo in punti 2D nel piano immagine.\n",
    "La matrice P verrà usata per proiettare sull'immagine del laboratorio tutti i punti appartenenti al pavimento(aventi coordinata Z=0); inoltre, al fine di misurare e quantificare la stima dei parametri ottenuti, verranno calcolati lo scarto quadratico medio e la deviazione standard della proiezione dei punti tramite la K-fold cross validation confrontando gli output dell'algoritmo implementato con quelli del metodo calibrateCamera contenuto nella libreria OpenCV2\n",
    "\n",
    "Per l'implementazione del codice sono state utilizzate le slide del corso e le seguenti documentazioni:\n",
    "\n",
    "numpy --> https://numpy.org/doc/1.24/reference/index.html#reference\n",
    "\n",
    "scipy --> https://docs.scipy.org/doc/scipy/reference/index.html#scipy-api\n",
    "\n",
    "opencv --> https://docs.opencv.org/4.x/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiamo inizialmente la corrispondenza di ogni punto tra le sue coordinate 3D e quelle 2D.\n",
    "Le coordinate 3D vengono prese rispetto al sistema di riferimento dell'immagine di calibrazione(il pattern a scacchiera nel nostro caso), mentre le coordinate 2D saranno i pixel corrispondenti.\n",
    "Nello specifico la matrice objp conterrà le coordinate nello spazio(ogni riga identifica un punto con 3 coordinate), la matrice imgp conterrà le posizioni dei pixel(ogni riga identifica un pixel) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import cv2\n",
    "\n",
    "'''\n",
    "def define_Points()\n",
    "\n",
    "Output\n",
    "------\n",
    "objp: Matrice 24X3 in cui ogni riga identifica un punto tramite le sue coordinate tridimensionali nel mondo\n",
    "imgp: Matrice 24X2 in cui ogni riga identifica un punto tramite le coordinate del pixel corrispondente nel piano immagine\n",
    "\n",
    "Tra objp e igmp c'è una corrispondenza 1 a 1, dove l'n-esima riga di objp e igmp identificano lo stesso punto in due sistemi di riferimento diversi\n",
    "------\n",
    "'''\n",
    "def define_Points():\n",
    "    nPunti = 24\n",
    "\n",
    "    #Punti 3D\n",
    "    objp = np.zeros((nPunti,3), np.float32)\n",
    "\n",
    "    objp[1,:] =[7, 0, 0]\n",
    "    objp[2,:] =[7, 0, 9]\n",
    "    objp[3,:] =[0, 4, 5]\n",
    "    objp[4,:] =[0, 3, 8]\n",
    "    objp[5,:] =[4, 4, 9]\n",
    "    \n",
    "    #first face\n",
    "    objp[1,:] =[7, 0, 0]\n",
    "    objp[2,:] =[7, 0, 9]\n",
    "    objp[3,:] =[0, 0, 7]\n",
    "    objp[4,:] =[3, 0, 4]\n",
    "\n",
    "    #second face\n",
    "    objp[5,:] =[0, 5, 0]\n",
    "    objp[6,:] =[0, 5, 7]\n",
    "    objp[7,:] =[0, 0, 9]\n",
    "\n",
    "    #top face\n",
    "    objp[8,:] =[7, 5, 9]\n",
    "    objp[9,:] =[4, 4, 9]\n",
    "\n",
    "    #additional points\n",
    "    objp[10,:] =[7, 0, 3]\n",
    "    objp[11,:] =[0, 3, 7]\n",
    "    objp[12,:] =[0, 5, 3]\n",
    "    objp[13,:] =[7, 2, 9]\n",
    "    \n",
    "    objp[14,:] =[0, 5, 9]\n",
    "    objp[15,:] =[1, 1, 9]\n",
    "    objp[16,:] =[4, 3, 9]\n",
    "    objp[17,:] =[5, 0, 5]\n",
    "    objp[18,:] =[1, 0, 6]\n",
    "    objp[19,:] =[4, 0, 8]\n",
    "    objp[20,:] =[0, 2, 6]\n",
    "    objp[21,:] =[0, 4, 1]\n",
    "    objp[22,:] =[0, 4, 5]\n",
    "    objp[23,:] =[0, 3, 8]\n",
    "\n",
    "    #Punti 2D\n",
    "    imgp = np.zeros((nPunti,2), np.float32)\n",
    "    \n",
    "    imgp[0,:] = [753, 599]\n",
    "    imgp[1,:] = [870, 533]\n",
    "    imgp[2,:] = [950, 329]\n",
    "    imgp[3,:] = [702, 419]\n",
    "    imgp[4,:] = [748, 353]\n",
    "    imgp[5,:] = [811, 287]\n",
    "    \n",
    "    #first face\n",
    "    imgp[0,:] = [753, 599]\n",
    "    imgp[1,:] = [870, 533]\n",
    "    imgp[2,:] = [950, 329]\n",
    "    imgp[3,:] = [815, 429]\n",
    "    imgp[4,:] = [842, 481]\n",
    "\n",
    "    #second face\n",
    "    imgp[5,:] = [654, 519]\n",
    "    imgp[6,:] = [695, 352]\n",
    "    imgp[7,:] = [833, 369]\n",
    "\n",
    "    #top face\n",
    "    imgp[8,:] = [838, 265]\n",
    "    imgp[9,:] = [811, 287]\n",
    "\n",
    "    #additional points\n",
    "    imgp[10,:] = [895, 471]\n",
    "    imgp[11,:] = [740, 381]\n",
    "    imgp[12,:] = [669, 453]\n",
    "    imgp[13,:] = [903, 299]\n",
    "    \n",
    "    imgp[14,:] = [710, 295]\n",
    "    imgp[15,:] = [828, 344]\n",
    "    imgp[16,:] = [834, 299]\n",
    "    imgp[17,:] = [885, 441]\n",
    "    imgp[18,:] = [825, 448]\n",
    "    imgp[19,:] = [898, 374]\n",
    "    imgp[20,:] = [755, 424]\n",
    "    imgp[21,:] = [677, 514]\n",
    "    imgp[22,:] = [702, 419]\n",
    "    imgp[23,:] = [748, 353]\n",
    "    \n",
    "    return objp, imgp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stampiamo i punti scelti sull'immagine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_points(imgp):\n",
    "    # Let's show the selected points \n",
    "    img = cv2.imread(\"imgs/cubotest.jpeg\")\n",
    "    img_to_show = img.copy()\n",
    "    for p in imgp:\n",
    "        img_to_show = cv2.circle(img_to_show, p.astype(np.int32), 3, (255, 0, 0))\n",
    "\n",
    "    cv2.imshow(\"img\", img_to_show)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "img = cv2.imread(\"imgs/cubotest.jpeg\")\n",
    "objp, imgp = define_Points()\n",
    "show_points(imgp)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementazione del metodo calibKRtp, che presi in input i punti 2D e 3D, restituisce le matrici dei parametri intrinseci ed estrinseci tramite la Direct Linear Transformation(DLT).\n",
    "\n",
    "La calibrazione della camera tramite DLT viene effettuata con i seguenti passi:\n",
    "\n",
    "1)Corrispondenza tra i punti 2D e 3D tramite matrice P:\n",
    "\n",
    "Per ogni punto, la coppia di coordinate 2D-3D è legata dalla seguente equazione:\n",
    "\n",
    "![image](eq1.png)\n",
    "\n",
    "Possiamo scomporre questa equazione nel prodotto scalare tra un vettore di termini noti e un vettore di incognite, e ricomporre il sistema:\n",
    "\n",
    "![image2](Ap.png)\n",
    "    \n",
    "2)Calcolo della matrice P:\n",
    "\n",
    "Dal sistema precedente, possiamo trovare il vettore p imponendo Ap=0 vincolando ||p||=1. Ciò equivale a imporre che p sia nell'intorno di raggio 1 di una ipersfera centrata in 0, ottenendo $A^TAp - \\lambda p^Tp=0$.\n",
    "\n",
    "Questo problema può essere risolto trovando gli autovalori di $A^TA$ tramite la decomposizione SVD, in particolare l'autovettore corrispondente all'autovalore minore sarà l'ultima colonna di $V^T$.\n",
    "\n",
    "Una volta trovato l'autovettore lo trasformo in una matrice 3x4:\n",
    "\n",
    "![image3](p.png)\n",
    "\n",
    "3)Applicazione della fattorizzazione RQ alla matrice P per trovare K=R e R=Q:\n",
    "\n",
    "Posso vedere p come il seguente prodotto tra matrici:\n",
    "\n",
    "![image4](rqfact.png)\n",
    "\n",
    "In cui la matrice K è una triangolare superiore ed R è ortogonale; entrambe le matrici possono essere trovate tramite la fattorizzazione RQ(dove K=R ed R=Q)\n",
    "\n",
    "4)Calcolo del vettore t:\n",
    "\n",
    "Una volta ottenuta K, $t=K^{-1}*[p_{1,4},p_{2,4},p_{3,4}]^T$ dalla seguente uguaglianza:\n",
    "\n",
    "![image5](t.png)\n",
    "\n",
    "Inoltre ai fini dell'assignment non si è tenuto conto di nessun tipo di distorsione radiale o tangenziale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice K(parametri intrinseci)\n",
      "[[940.47288546   4.57944922 732.13661551]\n",
      " [  0.         937.93103191 484.88644406]\n",
      " [  0.           0.           1.        ]]\n",
      "\n",
      "Matrice R\n",
      "[[ 0.64986409 -0.72161352  0.23864324]\n",
      " [-0.29297704 -0.52755395 -0.79740284]\n",
      " [ 0.70131385  0.44828648 -0.55425456]]\n",
      "\n",
      "Vettore t\n",
      "[ 0.75849521  3.91750797 31.65745269]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "def calibKRtp(imgp, objp)\n",
    "\n",
    "Input\n",
    "--------\n",
    "imgp, objp: Matrici in cui ogni riga indica un punto rispettivamente con le sue coordinate nel piano imagine e nel mondo\n",
    "--------\n",
    "\n",
    "Output\n",
    "--------\n",
    "K: Matrice dei parametri intrinseci\n",
    "R: Matrice di rotazione\n",
    "t: Vettore di traslazione\n",
    "p: Matrice camera\n",
    "--------\n",
    "'''\n",
    "\n",
    "def calibKRtp(imgp, objp):\n",
    "    \n",
    "    A=np.zeros((2*imgp.shape[0], 12))\n",
    "\n",
    "    #Creazione della matrice A, vista come il prodotto scalare tra il vettore dei termini noti(punti 2d e 3d) e il vettore delle incognite.\n",
    "    #Ogni punto è rappresentato da 2 equazioni\n",
    "    for i in range(imgp.shape[0]):\n",
    "        xp, yp=imgp[i,:]\n",
    "        X, Y, Z = objp[i,:]\n",
    "        A[2*i,:]=[0,0,0,0,X,Y,Z,1,-yp*X,-yp*Y,-yp*Z,-yp]\n",
    "        A[(2*i)+1,:]=[X,Y,Z,1,0,0,0,0,-xp*X,-xp*Y,-xp*Z,-xp]\n",
    "        \n",
    "    #Per risolvere il Constrained Least Square Problem si applica la SVD alla matrice A\n",
    "    #Nello specifico l'autovettore associato all'autovalore minore sarà l'ultima colonna della trasposta della matrice v\n",
    "    _, _, v = np.linalg.svd(A)\n",
    "    praw=v[-1,:]/v[-1,-1]\n",
    "    \n",
    "    #Trasformazione del vettore p in matrice, si possono ottenere la sottomarice 3x3 e l'ultima colonna, necessari per calcolare i parametri intrinseci ed estrinseci,\n",
    "    #tramite l'operazione di slicing sulla matrice p originaria\n",
    "    idx=0\n",
    "    p=np.reshape(praw,(3,4))\n",
    "    #p=p/p[2,3]\n",
    "    p13=p[:,:3]\n",
    "    p4=p[:,-1]\n",
    "\n",
    "    #Applicazione della fatorizzazione RQ alla sottomatrice 3x3 di p, con conseguente normalizzazione della matrice K in modo che K[3][3]=1\n",
    "    #Il vettore t sarà ottenuto da K^1*p4.T\n",
    "    K,R=sp.linalg.rq(p13)\n",
    "    t=np.matmul(np.linalg.inv(K),p4.T)\n",
    "    K=K/K[-1,-1]\n",
    "    \n",
    "    return K, R, t, p\n",
    "\n",
    "K, R, t, p = calibKRtp(imgp, objp)\n",
    "print(\"Matrice K(parametri intrinseci)\")\n",
    "print(K)\n",
    "print()\n",
    "print(\"Matrice R\")\n",
    "print(R)\n",
    "print()\n",
    "print(\"Vettore t\")\n",
    "print(t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per valutare la bontà della stima della matrice K ottenuta tramite l'implementazione della calibrazione DLT, verranno mostrate le differenze assolute tra la matrice K ottenuta dalla nostra implementazione e la K ottenuta tramite il metodo cv2.calibrateCamera rispettivamente con 6, 12 e 24 punti di calibrazione sull'immagine di test.\n",
    "Come parametro di distorsione non viene passato nulla.\n",
    "\n",
    "Di seguito il calcolo della matrice K tramite il metodo di OpenCV e a seguire le differenze assolute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 83.9815763    4.57944922 365.21115456]\n",
      " [  0.          80.21135961 164.18434015]\n",
      " [  0.           0.           0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#Fornisco una stima di K al metodo calibrateCamera\n",
    "Kcv = np.zeros((3,3))\n",
    "Kcv[0,0]=500\n",
    "Kcv[1,1]=500\n",
    "Kcv[2,2]=1\n",
    "Kcv[0,2]=img.shape[0]/2\n",
    "Kcv[1,2]=img.shape[1]/2\n",
    "\n",
    "_, Kcv, _, _, _ = cv2.calibrateCamera([objp], [imgp], img.shape[0:2], Kcv, None, flags=cv2.CALIB_USE_INTRINSIC_GUESS|cv2.CALIB_FIX_S1_S2_S3_S4| cv2.CALIB_ZERO_TANGENT_DIST| cv2.CALIB_FIX_K2 | cv2.CALIB_FIX_K3 )\n",
    "\n",
    "print(np.abs(K-Kcv))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](abs.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vengono definite le funzioni projection e draw_cube_points, che sfruttano il metodo di OpenCV2 projectPoints per ottenere i corrispettivi punti nel piano immagine a partire dalle coordinate nel mondo e dai parametri intrinseci ed estrinseci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total error: 4.285160889616237\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "def projection(objp, R, t, K)\n",
    "\n",
    "Input\n",
    "-------\n",
    "objp: Matrice in cui ogni riga contine le coordinate nel mondo di un punto\n",
    "R: Matrice di rotazione\n",
    "t: Vettore di traslazione\n",
    "K: Matrice dei parametri intrinseci\n",
    "-------\n",
    "\n",
    "Output\n",
    "-------\n",
    "imgpoints: Matrice che contiene le coordinate dei punti nel piano immagine\n",
    "-------\n",
    "'''\n",
    "\n",
    "def projection(objp, R, t, K):\n",
    "    imgpoints, _ = cv2.projectPoints(objp, R, t, K, np.zeros(5))\n",
    "    imgpoints = np.squeeze(imgpoints)\n",
    "    return imgpoints\n",
    "\n",
    "\n",
    "'''\n",
    "def draw_cube_points(K_, R_, t_)\n",
    "\n",
    "Input\n",
    "-------\n",
    "K: Matrice dei parametri intrinseci\n",
    "R: Matrice di rotazione\n",
    "t: Vettore di traslazione\n",
    "-------\n",
    "\n",
    "'''\n",
    "def draw_cube_points(K_, R_, t_):\n",
    "    #Creazione di una griglia che rappresenta tutti i punti apartenenti al pattern a scacchiera\n",
    "    points = []\n",
    "    for x in range(8):\n",
    "        for z in range(9):\n",
    "            points.append([x, 0, z])\n",
    "\n",
    "    for y in range(6):\n",
    "        for z in range(10):\n",
    "            points.append([0, y, z])\n",
    "        \n",
    "    for x in range(8):\n",
    "        for y in range(6):\n",
    "            points.append([x, y, 9])\n",
    "               \n",
    "    points = np.asarray(points).astype(np.float32)\n",
    "    projected_points = projection(points, R_, t_, K_).astype(np.int32)\n",
    "    img=cv2.imread(\"imgs/cubotest.jpeg\")\n",
    "    img_to_show_res = img.copy()\n",
    "    \n",
    "    #Stampa dei punti sull'immagine\n",
    "    for p in projected_points:\n",
    "        img_to_show_res = cv2.circle(img_to_show_res, p, 3, (255, 0, 0) )\n",
    "    \n",
    "    cv2.imshow(\"result\", img_to_show_res)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "imgpoints = projection(objp, R, t, K)\n",
    "\n",
    "#MSE tra i punti misurati e quelli ottenuti tramite il metodo projection\n",
    "mean_error = (cv2.norm(imgp, imgpoints, normType=cv2.NORM_L2)**2)/len(imgpoints)\n",
    "print( \"total error: {}\".format(mean_error) )\n",
    "\n",
    "draw_cube_points(K, R, t)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creazione dei due array che conterranno i punti presi nel sistema dell'immagine di riferimento e la loro corrispondenza in pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def createWorldPoints()\n",
    "\n",
    "Output\n",
    "------\n",
    "objp: Matrice 24X3 in cui ogni riga identifica un punto tramite le sue coordinate tridimensionali nel mondo\n",
    "imgp: Matrice 24X2 in cui ogni riga identifica un punto tramite le coordinate del pixel corrispondente nel piano immagine\n",
    "------\n",
    "'''\n",
    "\n",
    "def createWorldPoints():\n",
    "    #n_corners = 13\n",
    "    n_corners = 12\n",
    "    \n",
    "    #3D points\n",
    "    objp = np.zeros((n_corners,3), np.float32)\n",
    "    \n",
    "    #objp contiene i punti presi nel sistema di riferimento del laboratorio\n",
    "    #Punti a terra\n",
    "    objp[1,:] = [0, 265, 0]\n",
    "    objp[2,:] = [-94, 115, 0]\n",
    "    objp[3,:] = [65, 60, 0]\n",
    "    objp[4,:] = [0, 238, 0]\n",
    "    objp[5,:] = [140, -72, 0]\n",
    "    objp[6,:] = [-96, -132, 0]\n",
    "\n",
    "    #Punti nello spazio\n",
    "    objp[7, :] = [-135, 145, 70]\n",
    "    objp[8, :] = [0, 320, 66]\n",
    "    objp[9,:] = [65, 65, 80]\n",
    "    objp[10,:] = [-43, 348, 128]\n",
    "    objp[11,:] = [0, 348, 128]\n",
    "\n",
    "    #2D points\n",
    "    imgp = np.zeros((n_corners,2), np.float32)\n",
    "\n",
    "    #imgp contiene le coordinate dei pixel dei punti\n",
    "    imgp[0,:] = [604, 495]\n",
    "    imgp[1,:] = [624, 306]\n",
    "    imgp[2,:] = [453, 390]\n",
    "    imgp[3,:] = [729, 438]\n",
    "    imgp[4,:] = [622, 321]\n",
    "    imgp[5,:] = [839, 584]\n",
    "    imgp[6,:] = [345, 658]\n",
    "\n",
    "    #Punti nello spazio\n",
    "    imgp[7,:] = [381, 264]\n",
    "    imgp[8,:] = [626, 202]\n",
    "    imgp[9,:] = [737, 297]\n",
    "    imgp[10,:] = [575, 116]\n",
    "    imgp[11,:] = [630, 116]\n",
    "    \n",
    "    return objp, imgp\n",
    "\n",
    "objS, imgS=createWorldPoints()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcolo della Camera Matrix p e stampa dei punti di calibrazione presi sull'immagine del laboratorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera matrix p:\n",
      "[[ 2.16599000e+00  1.02745970e+00 -4.18595949e-01  6.00221385e+02]\n",
      " [ 2.64603063e-01 -2.26138041e-01 -1.94672540e+00  4.92219813e+02]\n",
      " [ 4.97033049e-04  1.51156643e-03 -7.42506612e-04  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "KS, RS, tS, pS = calibKRtp(imgS, objS)\n",
    "print(\"Camera matrix p:\")\n",
    "print(pS)\n",
    "img2 = cv2.imread(\"imgs/stanzavuota.jpeg\")\n",
    "img_to_show = img2.copy()\n",
    "for p in imgS:\n",
    "    img_to_show = cv2.circle(img_to_show, p.astype(np.int32), 3, (255, 0, 0) )\n",
    "\n",
    "cv2.imshow(\"img\", img_to_show)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementazione della K-fold cross validation:\n",
    "Il dataset viene suddiviso in K parti chiamate fold, iterativamente il k-esimo fold verrà usato come set di validazione mentre i restanti saranno usati come training.\n",
    "In questo modo ogni fold verrà utilizzato per la validazione del modello, riducendo quindi l'errore di overfitting dato dal riutilizzo degli stessi punti per la validazione\n",
    "\n",
    "Funzione draw_ground che stampa dei punti appartenenti al pavimento, cioè tutti i punti con coordinata Z=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def draw_ground(img2, pS)\n",
    "\n",
    "Input\n",
    "------\n",
    "img2: Immagine su cui verranno stampati i punti appartenenti al pavimento\n",
    "pS: Matrice camera utilizzata per proiettare i punti 3D nel piano immagine\n",
    "------\n",
    "'''\n",
    "\n",
    "def draw_ground(img2, pS):\n",
    "    xg = np.arange(-200, 170, 8) \n",
    "    yg = np.arange(-300, 350, 8)\n",
    "    #xg = np.arange(0, 10, 1) \n",
    "    #yg = np.arange(0, 10, 1)\n",
    "    xx, yy = np.meshgrid(xg, yg)\n",
    "\n",
    "    dim = xx.shape[0]*xx.shape[1]\n",
    "    floor3d = np.zeros((dim,4), np.float32)\n",
    "\n",
    "    xx = xx.reshape(dim)\n",
    "    yy = yy.reshape(dim)\n",
    "\n",
    "    floor3d[:,0] = xx \n",
    "    floor3d[:,1] = yy \n",
    "    floor3d[:,2] = np.zeros((dim))\n",
    "    floor3d[:,3] = 1\n",
    "\n",
    "    floorpx = np.zeros((floor3d.shape[0],3), np.float32)\n",
    "    index=0\n",
    "    for px in floorpx:\n",
    "        px=pS@floor3d[index].T\n",
    "        px=px/px[-1]\n",
    "        floorpx[index]=px\n",
    "        index+=1\n",
    "    floorpx = np.squeeze(floorpx).astype(np.int32)\n",
    "    ground=floorpx[:,:2]\n",
    "    img_to_show_res = img2.copy()\n",
    "    for p in ground:\n",
    "        img_to_show_res = cv2.circle(img_to_show_res, p, 3, (255, 0, 0) )\n",
    "\n",
    "    cv2.imshow(\"Punti pavimento(z=0)\", img_to_show_res)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "draw_ground(img2, pS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definisco la funzione drawFold, che presa in input la matrice p calcolata sul training set e i punti del test set, restituisce il MSE tra i punti del test set e i loro corrispondenti trovati tramite la proiezione della matrice p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def drawFold(p, testSet3d, testSetpx)\n",
    "\n",
    "Input\n",
    "------\n",
    "p: Matrice camera precedentemente stimata tramite il training set, in questa funzione viene utilizzata per calcolare l'MSE tra i punti misurati in laboratorio e quelli ottenuti dalla proiezione\n",
    "testSet3d: Testing set dei punti 3D utilizzati per ottenere la loro proiezione sul piano immagine tramite la matrice P\n",
    "testSetpx: Testing set dei punti appartenenti al piano immagine utilizzati per calcolare la MSE con i punti ottenuti dalla matrice P\n",
    "------\n",
    "\n",
    "Output\n",
    "------\n",
    "mse: Mean Squared Error(Errore Quadratico Medio) tra i punti appartenenti al piano immagine misurati in laboratorio e quelli ottenuti dalla proiezione tramite matrice P\n",
    "------\n",
    "'''\n",
    "\n",
    "def drawFold(p, testSet3d, testSetpx):\n",
    "    \n",
    "    index=0\n",
    "    f11=np.zeros((3,4), np.float32)\n",
    "    for x in testSet3d:\n",
    "            f11[index]=np.append(testSet3d[index], 1)\n",
    "            index+=1\n",
    "\n",
    "    floorpx = np.zeros((testSet3d.shape[0],3), np.float32)\n",
    "    index=0\n",
    "    for px in floorpx:\n",
    "        px=pS@f11[index].T\n",
    "        px=px/px[-1]\n",
    "        floorpx[index]=px\n",
    "        index+=1\n",
    "    floorpx = np.squeeze(floorpx).astype(np.int32)\n",
    "    ground=floorpx[:,:2]\n",
    "    imgfold = cv2.imread(\"imgs/stanzavuota.jpeg\")\n",
    "    img_to_show_res = imgfold.copy()\n",
    "    for p in ground:\n",
    "        img_to_show_res = cv2.circle(img_to_show_res, p, 3, (255, 0, 0) )\n",
    "\n",
    "    testSetpx = np.squeeze(testSetpx).astype(np.int32)\n",
    "    mse = (cv2.norm(testSetpx, ground, normType=cv2.NORM_L2)**2)/len(ground)\n",
    "\n",
    "    cv2.imshow(\"Punti pavimento(K-fold)\", img_to_show_res)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    return mse\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creazione di una funzione di shuffle per ordinare casualmente i punti del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def shuffle(a, b)\n",
    "\n",
    "Input\n",
    "------\n",
    "a, b: vettori che rappresentano il dataset dei punti\n",
    "------\n",
    "\n",
    "Output\n",
    "------\n",
    "shuffled_a, shuffled_b: vettori a e b con elementi ordinati casualmente\n",
    "------\n",
    "'''\n",
    "\n",
    "def shuffle(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    shuffled_a = np.empty(a.shape, dtype=a.dtype)\n",
    "    shuffled_b = np.empty(b.shape, dtype=b.dtype)\n",
    "    permutation = np.random.permutation(len(a))\n",
    "    for old_index, new_index in enumerate(permutation):\n",
    "        shuffled_a[new_index] = a[old_index]\n",
    "        shuffled_b[new_index] = b[old_index]\n",
    "    return shuffled_a, shuffled_b\n",
    "\n",
    "puntiLab, pxLab = createWorldPoints()\n",
    "\n",
    "puntiLab, pxLab=shuffle(puntiLab, pxLab)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcolo dell'MSE per ogni fold, MSE medio e deviazione standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Fold 1: 310.3333333333333\n",
      "MSE Fold 2: 294.6666666666667\n",
      "MSE Fold 3: 11.0\n",
      "MSE Fold 4: 13.333333333333336\n",
      "Mean MSE: 157.33333333333334\n",
      "Standard deviation: 145.27464411321827\n"
     ]
    }
   ],
   "source": [
    "#Creazione dei 4 fold a partire dai punti misurati in laboratorio\n",
    "f1 = puntiLab[0:3]\n",
    "f2 = puntiLab[3:6]\n",
    "f3 = puntiLab[6:9]\n",
    "f4 = puntiLab[9:12]\n",
    "\n",
    "p1 = pxLab[0:3]\n",
    "p2 = pxLab[3:6]\n",
    "p3 = pxLab[6:9]\n",
    "p4 = pxLab[9:12]\n",
    "\n",
    "#Stima di p e calcolo dell'MSE per ogni fold, con successivo calcolo di media e deviazione standard\n",
    "\n",
    "#test = f1 \n",
    "#training = f2 f3 f4\n",
    "_, _, _, pfold= calibKRtp(pxLab[3:12], puntiLab[3:12])\n",
    "mse1=drawFold(pfold, f1, p1)\n",
    "print(\"MSE Fold 1: {0}\".format(mse1))\n",
    "\n",
    "#test = f2 \n",
    "#training = f1 f3 f4\n",
    "_, _, _, pfold= calibKRtp(np.concatenate((p1, p3, p4)), np.concatenate((f1, f3, f4)))\n",
    "mse2=drawFold(pfold, f2, p2)\n",
    "print(\"MSE Fold 2: {0}\".format(mse2))\n",
    "\n",
    "#test = f3\n",
    "#training = f1 f2 f4\n",
    "_, _, _, pfold= calibKRtp(np.concatenate((p1, p2, p4)), np.concatenate((f1, f2, f4)))\n",
    "mse3=drawFold(pfold, f3, p3)\n",
    "print(\"MSE Fold 3: {0}\".format(mse3))\n",
    "\n",
    "#test = f4 \n",
    "#training = f1 f2 f3\n",
    "_, _, _, pfold= calibKRtp(pxLab[0:8], puntiLab[0:8])\n",
    "mse4=drawFold(pfold, f4, p4)\n",
    "print(\"MSE Fold 4: {0}\".format(mse4))\n",
    "\n",
    "#Media MSE e deviazione standard\n",
    "msetot=(mse1+mse2+mse3+mse4)/4\n",
    "print(\"Mean MSE: {0}\".format(msetot))\n",
    "sigma=np.sqrt(((mse1-msetot)**2+(mse2-msetot)**2+(mse3-msetot)**2+(mse4-msetot)**2)/4)\n",
    "print(\"Standard deviation: {0}\".format(sigma))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
